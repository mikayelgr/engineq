# Acura Curation Engine

Acura is the intelligent, asynchronous backend service responsible for music playlist curation within Project EngineQ. It operates as a dedicated worker process, consuming tasks from a RabbitMQ message queue and leveraging AI, external APIs, and a vector-enabled database to generate personalized playlists.

## Core Functionality & Architecture

Acura's primary role is to dynamically create or update music playlists for subscribers based on their preferences.

**Workflow:**

1.  **Task Trigger:** Acura listens for messages on the **`acura`** RabbitMQ queue. Each message typically contains a subscriber's `license` key, initiating a curation task for that subscriber. These messages are sent by the `ui` service when a user's playlist runs low.
2.  **Preference Ingestion:** Upon receiving a task, Acura fetches the subscriber's textual prompt (describing their desired music ambiance) from the PostgreSQL database.
3.  **Music Discovery Pipeline (`internal/chain.py`):** This is the heart of Acura, orchestrated using `pydantic-graph`. Key stages include:
    *   **AI-Powered Search Query Generation:** An LLM (configurable: OpenAI `gpt-4o-mini` by default, or a local Ollama model via `internal/agents/decide_llm()`) processes the subscriber's prompt to generate effective and unique search queries for Spotify.
    *   **Dynamic Curation Strategy (`SourceSelectionRouterNode`):**
        *   Generates embeddings for the search query using OpenAI's `text-embedding-3-large` model (1024 dimensions).
        *   Queries PostgreSQL (utilizing the `pgvector` extension) for existing tracks with similar embeddings and considers recently suggested tracks.
        *   Based on this analysis, it intelligently decides whether to curate entirely new content or to reuse/supplement existing similar content, optimizing for resource usage and content freshness.
    *   **New Content Curation Path:**
        *   Searches the Spotify API for playlists matching the AI-generated query.
        *   Employs an LLM to validate if the content of found Spotify playlists aligns with the user's original intent.
        *   For tracks from validated Spotify playlists (explicit tracks are filtered out):
            *   Finds corresponding music videos on YouTube using the Brave Search API.
            *   Verifies YouTube results for relevance using Levenshtein string similarity against track titles.
            *   Generates a contextualized track embedding (OpenAI `text-embedding-3-large`), incorporating the original search query, track title, and artist for better contextual relevance.
            *   Stores the verified track metadata (title, YouTube URL, artist, duration, Spotify image URL) and its embedding into the PostgreSQL database.
            *   Links the newly curated track to the subscriber's playlist.
    *   **Existing Content Reuse Path:**
        *   Identifies tracks in the database with embeddings similar to the current search query.
        *   Filters out tracks already suggested to the user recently to avoid repetition.
        *   Adds these existing, relevant tracks to the subscriber's playlist.
4.  **Database Interaction:** All database operations are managed via SQLAlchemy models (auto-generated by `sqlacodegen` into `internal/models/codegen/models.py`) and Data Access Objects (DAOs in `internal/models/dao.py`).
5.  **Asynchronous Operations:** Built entirely with `asyncio`, using `aio_pika` for RabbitMQ communication and `asyncpg` for non-blocking PostgreSQL interactions.

**Key Modules:**

*   **`__main__.py`**: Entry point of the service; initializes connections (PostgreSQL, RabbitMQ), logging (including Logfire), and starts the RabbitMQ message consumer.
*   **`internal/conf.py`**: Manages application configuration, loading values from environment variables.
*   **`internal/mq.py`**: Handles RabbitMQ connection, message consumption from the "acura" queue, and task dispatching to the curation logic.
*   **`internal/chain.py`**: Contains the core `MusicDiscoveryPipeline` and its constituent nodes.
*   **`internal/agents/`**: Configures the LLM (OpenAI or Ollama) used by `pydantic-ai` agents.
*   **`internal/services/`**: Contains clients for interacting with external services:
    *   `spotify.py`: Spotify API client.
    *   `brave_search.py`: Brave Search API client.
    *   `embeddings.py`: OpenAI Embeddings API client.
*   **`internal/models/`**: Manages database schema definitions (SQLAlchemy models) and data access (DAOs, SQL connection).

## Requirements

*   Python 3.11+
*   RabbitMQ server
*   PostgreSQL server (version compatible with `pgvector`)
*   `uv` package manager (for development and running scripts)

## Environment Variables

Acura requires the following environment variables to be set (e.g., in an `acura/.env` file for local development):

*   **`DEBUG`**: Set to `1` for debug logging, `0` for production. (Default: `1` in example)
*   **`POSTGRES_URL`**: PostgreSQL connection string.
    *   *Example:* `postgresql+asyncpg://postgres:postgres@localhost:5432/engineq`
*   **`MIGRATION_URL`**: Same as `POSTGRES_URL` but append `?sslmode=disable` in the end of the URL if running locally with SSL disabled for PostgreSQL.
*   **`AMQP_URL`**: RabbitMQ connection string.
    *   *Example:* `amqp://guest:guest@localhost:5672/`
*   **`OPENAI_API_KEY`**: Your API key for OpenAI services (LLMs and embeddings).
*   **`SPOTIFY_CLIENT_ID`**: Your Spotify API client ID.
*   **`SPOTIFY_CLIENT_SECRET`**: Your Spotify API client secret.
*   **`BRAVE_SEARCH_TOKEN`**: Your API token for the Brave Search API.
*   **`LOGFIRE_TOKEN`**: Token for Logfire (Pydantic AI observability).
*   **`OLLAMA_API_URL`** (Optional): Base URL for a local Ollama API if you want to use local LLMs.
    *   *Example:* `http://localhost:11434/v1`
*   **`OLLAMA_MODEL_NAME`** (Optional): Name of the Ollama model to use (e.g., `qwen2.5:7b-instruct`). If set, overrides the default OpenAI model for agent tasks.

## Development Setup & Running

1.  **Prerequisites:** Ensure Python 3.11+, `uv`, Docker, and Docker Compose are installed.
2.  **Dependent Services:** Start PostgreSQL and RabbitMQ. Refer to the root `README.md` for Docker Compose examples.
3.  **Environment Variables:** Copy `acura/.env.example` to `acura/.env` and populate it with your actual credentials and URLs.
4.  **Install Dependencies:** From the `acura/` directory:
    ```bash
    uv venv
    source .venv/bin/activate
    uv sync
    ```
5.  **Start the Acura Service:** From the `acura/` directory:
    ```bash
    uv run just start
    ```
    Acura will connect to RabbitMQ and PostgreSQL and start listening for messages on the "acura" queue. Note that pending migrations will be
    applied automatically in this case.

## Containerization

A `Dockerfile` is provided to build a container image for Acura.
*   **Build Image (from project root):** `docker build -t engineq-acura ./acura`
*   **Run Container:** Ensure all necessary environment variables listed above are passed to the container at runtime. The container entry point is `poetry run python .`, which executes `acura/__main__.py`. Refer to the root `README.md` for example `docker run` commands and further deployment context.
```
